"""
Multi-Agent Analyst Module
Orchestrates a debate between multiple AI agents with different personas to analyze a stock.
"""
import asyncio
import json
import logging
from typing import Dict, Any, List, AsyncGenerator
from datetime import datetime

# Import low-level API callers from llm_analyst
from llm_analyst import generate_analysis_openai, generate_analysis_gemini

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StockAnalystAgent:
    """
    Represents a single specialized analyst agent.
    """

    def __init__(self, slug: str, name: str, role: str, description: str, system_prompt: str, template: str = None):
        self.slug = slug
        self.name = name
        self.role = role
        self.description = description
        self.system_prompt = system_prompt
        self.template = template

    async def analyze(self, context: str, api_config: Dict[str, Any]) -> str:
        """
        Perform analysis based on the agent's persona.
        """
        # Load Template if available
        prompt = ""
        if self.template:
            from jinja2 import Template
            t = Template(self.template)
            prompt = t.render(
                name=self.name, 
                role=self.role, 
                description=self.description, 
                context=context
            )
        else:
            # Fallback Legacy
            prompt = f"""
è¯·ä½ æ‰®æ¼”ã€{self.name}ã€‘ï¼ˆ{self.role}ï¼‰ã€‚
ä½ çš„æ ¸å¿ƒèŒè´£æ˜¯ï¼š{self.description}

{context}

è¯·æ ¹æ®ä»¥ä¸Šæ•°æ®ï¼Œç»™å‡ºä½ çš„ä¸“ä¸šåˆ†ææ„è§ã€‚
è¦æ±‚ï¼š
1. ä¸¥æ ¼éµå®ˆä½ çš„äººè®¾ï¼Œä¸è¦è¯•å›¾å¹³è¡¡è§‚ç‚¹ï¼Œé‚£æ˜¯CIOçš„å·¥ä½œã€‚
2. è§‚ç‚¹å¿…é¡»é²œæ˜ï¼Œæœ‰ç†æœ‰æ®ã€‚
3. å¦‚æœæ•°æ®ä¸è¶³ä»¥æ”¯æŒä½ çš„é¢†åŸŸåˆ†æï¼Œç›´æ¥æŒ‡å‡ºã€‚
4. è¾“å‡ºæ ¼å¼ä¸ºMarkdownï¼Œä¸è¦åŒ…å«å¯’æš„ã€‚
"""
        # Log the full prompt
        print(f"\n======== [Agent Prompt Debug: {self.name}] ========\n{prompt}\n===================================================\n")

        # Call LLM
        # We construct a fake stock_info/tech_data to satisfy the function signature if we reuse llm_analyst, 
        # OR we call the low-level functions directly. 
        # Calling low-level functions is better.
        
        provider = api_config.get('provider', 'openai')
        
        try:
            return await self._call_llm_direct(prompt, api_config)
                
        except Exception as e:
            logger.error(f"Agent {self.name} failed: {e}")
            return f"**{self.name} åˆ†æå¤±è´¥**: {str(e)}"

    async def _call_llm_direct(self, prompt: str, api_config: Dict[str, Any]) -> str:
        """
        Direct LLM call bypassing llm_analyst's specific prompt construction logic.
        Supports OpenAI and Gemini.
        """
        provider = api_config.get('provider', 'openai')
        
        if provider == 'gemini':
            # Gemini Implementation
            try:
                # Lazy import to avoid dependency issues if not installed
                from google import genai
                from google.genai import types
                import os
                
                if api_config.get('credentials_path') and os.path.exists(api_config['credentials_path']):
                    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = api_config['credentials_path']
                
                client = genai.Client(
                    vertexai=True,
                    project=api_config['project_id'],
                    location=api_config['location']
                )
                
                response = client.models.generate_content(
                    model=api_config.get('model', 'gemini-2.5-flash'),
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        temperature=0.3,
                        max_output_tokens=4096,
                        system_instruction=self.system_prompt
                    )
                )
                
                if hasattr(response, 'text'):
                    return response.text
                elif hasattr(response, 'candidates') and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        return ''.join([part.text for part in candidate.content.parts if hasattr(part, 'text')])
                return str(response)
                
            except ImportError:
                return "Google Gen AI SDK not installed."
            except Exception as e:
                return f"Gemini API Error: {str(e)}"

        else:
            # OpenAI / DeepSeek / GLM Implementation
            try:
                from openai import OpenAI
                
                client = OpenAI(
                    api_key=api_config['api_key'],
                    base_url=api_config['base_url']
                )
                
                api_params = {
                    "model": api_config['model'],
                    "messages": [
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.3,
                    "max_tokens": 4096
                }
                
                # Special handling for GLM thinking mode disable
                if provider == "glm":
                    api_params["extra_body"] = {"thinking": {"type": "disabled"}}

                response = client.chat.completions.create(**api_params)
                return response.choices[0].message.content
                
            except Exception as e:
                return f"OpenAI/Compatible API Error: {str(e)}"


class MultiAgentSystem:
    def __init__(self, api_config: Dict[str, Any]):
        self.api_config = api_config
        self.agents = []
        self._load_agents()

    def _load_agents(self):
        """Load agents configuration from database"""
        import database
        
        # Define the mapping of agents to DB slugs
        agent_configs = [
            {"slug": "agent_technician", "fallback_name": "æŠ€æœ¯æ´¾ (Technician)"},
            {"slug": "agent_risk_officer", "fallback_name": "é£æ§å®˜ (Risk Officer)"},
            {"slug": "agent_fundamentalist", "fallback_name": "åŸºæœ¬é¢ (Fundamentalist)"}
        ]
        
        self.agents = []
        
        for cfg in agent_configs:
            strategy = database.get_strategy_by_slug(cfg['slug'])
            if strategy:
                self.agents.append(StockAnalystAgent(
                    slug=cfg['slug'],
                    name=strategy['name'],
                    role=strategy['params'].get('role', 'Experts'),
                    description=strategy.get('description', ''),
                    system_prompt=strategy['params'].get('system_prompt', ''),
                    template=strategy.get('template_content')
                ))
            else:
                # Add a dummy fallback or raise error
                print(f"âš ï¸ Warning: Agent strategy {cfg['slug']} not found in DB. Using fallback.")
                # This ensures system doesn't crash if DB init failed
                pass

        # Load CIO
        cio_slug = "agent_cio"
        strategy = database.get_strategy_by_slug(cio_slug)
        if strategy:
            self.cio = StockAnalystAgent(
                slug=cio_slug,
                name=strategy['name'],
                role=strategy['params'].get('role', 'CIO'),
                description=strategy.get('description', ''),
                system_prompt=strategy['params'].get('system_prompt', ''),
                template=strategy.get('template_content')
            )
        else:
             print(f"âš ï¸ Warning: CIO strategy {cio_slug} not found in DB.")


    async def run_debate_stream(self, stock_info: Dict[str, Any], tech_data: Dict[str, Any], realtime_data: Dict[str, Any], start_progress: int = 30) -> AsyncGenerator[str, None]:
        """
        Run the debate and yield SSE events.
        Format: JSON string for SSE data.
        """
        # 1. Prepare Basic Data (Common Context)
        asset_type = stock_info.get('asset_type', 'stock')
        
        # Fix Price 0 issue
        price = realtime_data.get('price')
        if not price or float(price) == 0:
             price = tech_data.get('close', 0)
        if not price or float(price) == 0:
             price = tech_data.get('realtime_price', 0)
        if (not price or float(price) == 0):
             if tech_data.get('ma5'): price = tech_data.get('ma5')
             elif tech_data.get('ma20'): price = tech_data.get('ma20')

        current_date = datetime.now().strftime('%Y-%m-%d')
        
        # Common Context (Shared by all)
        common_context = f"""
**åˆ†æå¯¹è±¡**ï¼š{stock_info['name']} ({stock_info['symbol']}) [{asset_type.upper()}]
**åˆ†ææ—¥æœŸ**ï¼š{current_date}
**å½“å‰ä»·æ ¼**ï¼š{price} (æ¶¨è·Œ: {realtime_data.get('change_pct', 0)}%)
**å¸‚åœºå¤§ç›˜**ï¼š{realtime_data.get('market_index_price', 'N/A')} ({realtime_data.get('market_index_change', 0)}%)
"""

        # --- Enhanced Data Fetching ---
        news_context = ""
        funds_context = ""
        financial_context = ""
        
        try:
            from data_provider.akshare_fetcher import AkshareFetcher
            full_fetcher = AkshareFetcher(sleep_min=0.1, sleep_max=0.5)
            
            yield json.dumps({"type": "step", "content": "ğŸ“¡ æ­£åœ¨å¹¶è¡Œè·å–ï¼šåŸºæœ¬é¢æ•°æ®ã€èµ„é‡‘æµå‘ã€æœ€æ–°èµ„è®¯..."})
            
            # Run fetches in executor to verify non-blocking IO if possible, or just synchronous for now
            # In production, these should be async. Here we use sync calls but they are fast enough or worth waiting.
            
            # 1. News
            news_items = full_fetcher.get_stock_news(stock_info['symbol'])
            if news_items:
                news_context = "\n**è¿‘æœŸé‡è¦èµ„è®¯**ï¼š\n"
                for item in news_items[:3]:
                    news_context += f"- [{item['date']}] {item['title']}\n"
            
            # 2. Funds Flow (For Technician)
            funds_data = full_fetcher.fetch_money_flow(stock_info['symbol'])
            if funds_data and funds_data.get('status') == 'success':
                net_main = funds_data.get('net_amount_main', 0) / 10000.0 # ä¸‡
                net_main_str = f"{net_main:.2f}ä¸‡" if abs(net_main) < 10000 else f"{net_main/10000:.2f}äº¿"
                
                funds_context = f"""
**èµ„é‡‘æµå‘æ•°æ®**ï¼š
- ä¸»åŠ›å‡€æµå…¥ï¼š{net_main_str} (å æ¯”: {funds_data.get('net_pct_main', 0)}%)
- è¶…å¤§å•å‡€æµå…¥ï¼š{funds_data.get('net_amount_super', 0)/10000:.2f}ä¸‡
- æ¶¨è·Œå¹…ï¼š{funds_data.get('change_pct', 0)}%
"""
            
            # 3. Financials (For Fundamentalist)
            reports_data = full_fetcher.fetch_financial_report(stock_info['symbol'])
            if reports_data and reports_data.get('data'):
                latest_date = reports_data.get('latest_date', 'N/A')
                latest_report = reports_data['data'].get(latest_date, {})
                
                # Extract key metrics if available (Handling potential key variations)
                # Akshare abstract often has: 'å½’æ¯å‡€åˆ©æ¶¦', 'è¥ä¸šæ€»æ”¶å…¥', 'å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿', etc.
                # Try to get raw dump of key fields
                financial_context = f"\n**æ ¸å¿ƒè´¢åŠ¡æ•°æ® (æœ€æ–°æŠ¥å‘ŠæœŸ: {latest_date})**ï¼š\n"
                key_fields = ['è¥ä¸šæ€»æ”¶å…¥', 'å½’æ¯å‡€åˆ©æ¶¦', 'æ‰£éå‡€åˆ©æ¶¦', 'åŸºæœ¬æ¯è‚¡æ”¶ç›Š', 'å‡€èµ„äº§æ”¶ç›Šç‡']
                
                for k, v in latest_report.items():
                    for target in key_fields:
                        if target in k:
                            financial_context += f"- {k}: {v}\n"
                            
            yield json.dumps({"type": "step", "content": "âœ… å¤šç»´åº¦æ·±åº¦æ•°æ®è·å–å®Œæˆ"})

        except Exception as e:
            logger.error(f"Enhanced fetch failed: {e}")
            yield json.dumps({"type": "step", "content": f"âš ï¸ æ•°æ®å¢å¼ºéƒ¨åˆ†å¤±è´¥: {str(e)}"})

        # --- Construct Specialized Contexts ---
        
        # 1. Technician Context
        # Structure: K-Line Pattern, MA, Support/Resistance, Funds Flow, News
        pattern_str = ", ".join(tech_data.get('pattern_details', [])) or "æ— æ˜æ˜¾å½¢æ€"
        tech_context = f"""
{common_context}

**æŠ€æœ¯é¢æ·±åº¦æ•°æ®**ï¼š
- å‡çº¿ç³»ç»Ÿï¼šMA5={tech_data.get('ma5')}, MA20={tech_data.get('ma20')}, MA60={tech_data.get('ma60')}
- å‡çº¿æ’åˆ—ï¼š{tech_data.get('ma_arrangement', 'æœªçŸ¥')}
- Kçº¿å½¢æ€ï¼š{pattern_str} (å½¢æ€åˆ†: {tech_data.get('pattern_score', 0)})
- ç›¸å¯¹å¼ºå¼±(RSI)ï¼š{tech_data.get('rsi', 'N/A')}
- æ”¯æ’‘/å‹åŠ›ï¼šæ”¯æ’‘ä½ {tech_data.get('support', 'N/A')}, å‹åŠ›ä½ {tech_data.get('resistance', 'N/A')}
- æ³¢åŠ¨ç‡(ATR)ï¼š{tech_data.get('atr_pct', 'N/A')}%
{funds_context}
{news_context}
"""

        # 2. Fundamentalist Context
        # Structure: Valuation (PE/PB), Financials, Sector Rank, long-term trend (MA60)
        # Assuming realtime_data has PE/PB
        pe = realtime_data.get('pe_ratio', 'N/A')
        pb = realtime_data.get('pb_ratio', 'N/A')
        total_mv = realtime_data.get('total_mv', 'N/A')
        
        fund_context = f"""
{common_context}

**åŸºæœ¬é¢æ·±åº¦æ•°æ®**ï¼š
- ä¼°å€¼æŒ‡æ ‡ï¼šPE(åŠ¨æ€)={pe}, PB={pb}, æ€»å¸‚å€¼={total_mv}
- è´¢åŠ¡æ‘˜è¦ï¼š
{financial_context if financial_context else "æš‚æ— è¯¦ç»†è´¢æŠ¥æ•°æ®"}
- é•¿æœŸè¶‹åŠ¿ï¼šMA60={tech_data.get('ma60')} (ç‰›ç†Šåˆ†ç•Œ)
{news_context}
"""

        # 3. Risk Context
        # Structure: Volatility, Market Environment, Stop Loss, Position Sizing hints
        risk_context = f"""
{common_context}

**é£æ§æ ¸å¿ƒæŒ‡æ ‡**ï¼š
- æ³¢åŠ¨ç‡(ATR%)ï¼š{tech_data.get('atr_pct', 'N/A')}% (é«˜æ³¢åŠ¨éœ€é™ä»“)
- å¸‚åœºç¯å¢ƒï¼š{realtime_data.get('market_index_change', 0)}% (å¤§ç›˜æ¶¨è·Œ)
- ç›ˆäºæ¯”è¯„ä¼°ï¼šä¸Šæ–¹å‹åŠ› {tech_data.get('resistance', 'N/A')} vs ä¸‹æ–¹æ”¯æ’‘ {tech_data.get('support', 'N/A')}
- ä¹–ç¦»ç‡ï¼šå½“å‰ä»·æ ¼è·ç¦» MA20 {(float(price) - float(tech_data.get('ma20', price)))/float(tech_data.get('ma20', 1))*100:.2f}%
{news_context}
"""

        # Dispatcher Map
        context_map = {
            "agent_technician": tech_context,
            "agent_fundamentalist": fund_context,
            "agent_risk_officer": risk_context
        }

        yield json.dumps({"type": "progress", "value": start_progress, "message": "åˆå§‹åŒ–å¤šæ™ºèƒ½ä½“è¾©è®ºç¯å¢ƒ..."})
        yield json.dumps({"type": "step", "content": "ğŸ”” è¾©è®ºç»„å»ºå®Œæ¯•ï¼Œå‡†å¤‡å¼€å§‹..."})
        yield json.dumps({"type": "token", "content": "\n\n# ğŸ¤– AI ä¸“å®¶å›¢é˜Ÿè¾©è®ºçºªè¦\n\n"})
        
        agent_results = []
        tasks = []
        total_agents = len(self.agents)
        current_progress = start_progress + 5
        yield json.dumps({"type": "progress", "value": current_progress, "message": "ä¸“å®¶å›¢é˜Ÿå¼€å§‹å¹¶è¡Œåˆ†æ..."})

        for i, agent in enumerate(self.agents):
            # Select specific context or fallback to common
            my_context = context_map.get(agent.slug, common_context + news_context)
            tasks.append(agent.analyze(my_context, self.api_config))
        
        results = await asyncio.gather(*tasks)
        
        debate_content = ""
        progress_range_agents = 45
        
        for i, res in enumerate(results):
            agent = self.agents[i]
            inc = int(((i + 1) / total_agents) * progress_range_agents)
            progress_pct = current_progress + inc
            
            yield json.dumps({"type": "progress", "value": progress_pct, "message": f"{agent.name} å®Œæˆåˆ†æ"})
            yield json.dumps({"type": "step", "content": f"âœ… {agent.name} æäº¤äº†åˆ†ææŠ¥å‘Š"})

            section_html = f"""
<details class="mb-3 group border border-gray-700/50 rounded-lg bg-gray-800/30 overflow-hidden">
    <summary class="cursor-pointer p-3 hover:bg-white/5 transition-colors flex items-center justify-between select-none list-none text-sm outline-none">
        <div class="flex items-center gap-2 font-bold text-indigo-300">
            <span>ğŸ‘¤</span>
            <span>{agent.name} åˆ†ææŠ¥å‘Š</span>
        </div>
        <span class="text-xs text-gray-500 transition-transform duration-200 group-open:rotate-180">â–¼</span>
    </summary>
    <div class="p-4 pt-2 border-t border-dashed border-gray-700/50 text-sm text-gray-300 leading-relaxed font-sans mt-2">
{res.replace(chr(10), '<br/>')}
    </div>
</details>
<div class="h-2"></div>
"""
            debate_content += section_html
            yield json.dumps({"type": "token", "content": section_html})
            agent_results.append(f"ã€{agent.name}æ„è§ã€‘:\n{res}")

        # 3. Round 2: CIO Decision
        yield json.dumps({"type": "step", "content": "ğŸ¤” é¦–å¸­æŠ•èµ„å®˜ (CIO) æ­£åœ¨æ±‡æ€»ä¸“å®¶æ„è§..."})
        yield json.dumps({"type": "progress", "value": 85, "message": "é¦–å¸­æŠ•èµ„å®˜ (CIO) æ­£åœ¨åˆ¶å®šæœ€ç»ˆå†³ç­–..."})
        
        # CIO sees Common Context + All Opinions
        cio_context = f"""
{common_context}
{news_context}

**ä¸“å®¶å›¢é˜Ÿè¾©è®ºæ‘˜è¦**ï¼š
{''.join(agent_results)}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œè¿›è¡Œæœ€ç»ˆæ€»ç»“å’Œå†³ç­–ã€‚
"""
        cio_result = await self.cio.analyze(cio_context, self.api_config)
        
        yield json.dumps({"type": "progress", "value": 95, "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š..."})
        yield json.dumps({"type": "step", "content": "âœï¸ CIO æ­£åœ¨ç­¾ç½²æœ€ç»ˆè£å†³ä¹¦..."})

        cio_header = "\n\n### ğŸ–ï¸ é¦–å¸­æŠ•èµ„å®˜ (CIO) æœ€ç»ˆè£å†³\n\n"
        yield json.dumps({"type": "token", "content": cio_header})
        
        chunk_size = 8
        for i in range(0, len(cio_result), chunk_size):
            chunk = cio_result[i:i+chunk_size]
            yield json.dumps({"type": "token", "content": chunk})
            await asyncio.sleep(0.01)
            
        cio_section = cio_header + cio_result + "\n\n"
        full_report = debate_content + cio_section
        
        yield json.dumps({"type": "progress", "value": 100, "message": "åˆ†æå®Œæˆ"})
        yield json.dumps({"type": "final_html", "content": full_report})
        yield json.dumps({"type": "complete", "content": "Done"})
